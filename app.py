# â†‘ %%writefile app.py ã¯GitHubã«ã¯å«ã‚ãªã„ã§ãã ã•ã„ï¼
import streamlit as st
# --- Set page config FIRST ---
st.set_page_config(page_title="AIãƒãƒŠãƒ¼ãƒ©ãƒ•ç”Ÿæˆ", layout="wide")

# --- Libraries ---
from openai import OpenAI # Step 1, 2 ã§ä½¿ç”¨
import vertexai # â˜… Vertex AI ã‚’ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
from vertexai.preview.vision_models import ImageGenerationModel # â˜… Imagenãƒ¢ãƒ‡ãƒ«ã‚’ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
# import requests # URLãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ä¸è¦ã®ãŸã‚ã‚³ãƒ¡ãƒ³ãƒˆã‚¢ã‚¦ãƒˆã¾ãŸã¯å‰Šé™¤
from PIL import Image, ImageDraw, ImageFont
from io import BytesIO
import time
import base64
import os

# --- Function to load prompts from files ---
def load_prompt(file_path):
    """æŒ‡å®šã•ã‚ŒãŸãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹ã‹ã‚‰ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’èª­ã¿è¾¼ã‚€"""
    if not os.path.exists(file_path):
        st.error(f"ã‚¨ãƒ©ãƒ¼: ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {file_path}")
        return None
    try:
        with open(file_path, 'r', encoding='utf-8') as f:
            return f.read()
    except Exception as e:
        st.error(f"ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼ ({file_path}): {e}")
        return None

# --- Load Prompts from Files ---
layout_analysis_prompt_text = load_prompt("prompts/layout_analysis_prompt.txt")
dalle_instruction_template_text = load_prompt("prompts/dalle_prompt_instruction_template.txt") # åå‰ã¯ãã®ã¾ã¾æµç”¨
prompts_loaded = layout_analysis_prompt_text is not None and dalle_instruction_template_text is not None

# --- Load API Keys & GCP Config ---
secrets_ok = False
GCP_PROJECT_ID = None
GCP_REGION = None
OPENAI_API_KEY = None

if prompts_loaded:
    try:
        # â˜… GCPãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆIDã¨ãƒªãƒ¼ã‚¸ãƒ§ãƒ³ã‚’Secretsã‹ã‚‰èª­ã¿è¾¼ã‚€
        GCP_PROJECT_ID = st.secrets["GCP_PROJECT_ID"]
        GCP_REGION = st.secrets["GCP_REGION"]
        OPENAI_API_KEY = st.secrets["OPENAI_API_KEY"] # GPT-4oç”¨ã«å¿…è¦
        # GOOGLE_API_KEY = st.secrets["GOOGLE_API_KEY"] # Vertex AIã§ã¯é€šå¸¸ä¸è¦

        if not GCP_PROJECT_ID or not GCP_REGION or not OPENAI_API_KEY:
            st.error("ã‚¨ãƒ©ãƒ¼: Secretsã«ã‚­ãƒ¼(GCP_PROJECT_ID, GCP_REGION, OPENAI_API_KEY)ãŒä¸è¶³ã—ã¦ã„ã¾ã™ã€‚")
            st.stop()
        secrets_ok = True
    except KeyError as e:
        st.error(f"ã‚¨ãƒ©ãƒ¼: Secretsã«ã‚­ãƒ¼ '{e}' ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚")
        st.stop()
    except Exception as e:
         st.error(f"Secretsèª­ã¿è¾¼ã¿ä¸­ã«äºˆæœŸã›ã¬ã‚¨ãƒ©ãƒ¼: {e}")
         st.stop()

# --- API Function Definitions ---
if secrets_ok and prompts_loaded:

    # analyze_layout_with_gpt4o (å¤‰æ›´ãªã— - OpenAIã‚’ä½¿ç”¨)
    def analyze_layout_with_gpt4o(image_bytes, api_key, layout_prompt_text):
        # ... (é–¢æ•°å®šç¾©ã¯å‰å›ã¨åŒã˜) ...
        if not layout_prompt_text: st.error("ãƒ¬ã‚¤ã‚¢ã‚¦ãƒˆè§£æãƒ—ãƒ­ãƒ³ãƒ—ãƒˆæœªèª­è¾¼"); return None
        try:
            client = OpenAI(api_key=api_key)
            # ... (base64, mime type, API call) ...
            base64_image = base64.b64encode(image_bytes).decode('utf-8')
            try: img = Image.open(BytesIO(image_bytes)); img_format = img.format
            except: img_format = None
            if img_format == 'PNG': mime_type = "image/png"
            elif img_format in ['JPEG', 'JPG']: mime_type = "image/jpeg"
            else: mime_type = "image/jpeg"
            prompt_messages = [{"role": "user", "content": [{"type": "text", "text": layout_prompt_text}, {"type": "image_url", "image_url": {"url": f"data:{mime_type};base64,{base64_image}"}}]}]
            response = client.chat.completions.create(model="gpt-4o", messages=prompt_messages, max_tokens=1000)
            if response.choices and response.choices[0].message.content: return response.choices[0].message.content.strip()
            else: st.warning(f"GPT-4oå¿œç­”ãªã—(ãƒ¬ã‚¤ã‚¢ã‚¦ãƒˆè§£æ). R: {response}"); return None
        except Exception as e: st.error(f"GPT-4o APIã‚¨ãƒ©ãƒ¼(ãƒ¬ã‚¤ã‚¢ã‚¦ãƒˆè§£æ): {e}"); return None


    # generate_dalle_prompt_with_gpt4o (å¤‰æ›´ãªã— - OpenAIã‚’ä½¿ç”¨)
    # é–¢æ•°åã¯ãã®ã¾ã¾ä½¿ã†ãŒã€ç”Ÿæˆã™ã‚‹ã®ã¯Imagenå‘ã‘ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã«ãªã‚‹ç‚¹ã«æ³¨æ„
    def generate_dalle_prompt_with_gpt4o(layout_info, impression, details, size, api_key, dalle_instruction_template_text):
        """OpenAI GPT-4o APIã‚’å‘¼ã³å‡ºã—ã€ç”»åƒç”Ÿæˆç”¨ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’ç”Ÿæˆã™ã‚‹é–¢æ•°"""
        # ... (é–¢æ•°å®šç¾©ã¯å‰å›ã¨åŒã˜ã€ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆã«å¾“ã£ã¦ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’ç”Ÿæˆ) ...
        if not dalle_instruction_template_text: st.error("ç”»åƒç”ŸæˆæŒ‡ç¤ºãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆæœªèª­è¾¼"); return None
        try:
            client = OpenAI(api_key=api_key)
            prompt_generation_instruction = dalle_instruction_template_text.format(
                 size=size, layout_info=layout_info, impression=impression, details=details
            ) # Note: size format might need adjustment for Imagen later
            response = client.chat.completions.create(
                model="gpt-4o", messages=[{"role": "user", "content": prompt_generation_instruction}], max_tokens=1500
            )
            if response.choices and response.choices[0].message.content: return response.choices[0].message.content.strip()
            else: st.warning(f"GPT-4oå¿œç­”ãªã—(ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆç”Ÿæˆ). R: {response}"); return None
        except Exception as e: st.error(f"GPT-4o APIã‚¨ãƒ©ãƒ¼(ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆç”Ÿæˆ): {e}"); return None


    # â–¼â–¼â–¼ DALL-E 3 ã®ä»£ã‚ã‚Šã« Imagen ã‚’ä½¿ã†é–¢æ•° â–¼â–¼â–¼
    def generate_image_with_imagen(prompt, project_id, region):
        """Vertex AI Imagen APIã‚’å‘¼ã³å‡ºã—ã€ç”»åƒãƒã‚¤ãƒˆã‚’è¿”ã™é–¢æ•°"""
        try:
            # Vertex AIã‚’åˆæœŸåŒ– (æ¯å›å‘¼ã‚“ã§ã‚‚å•é¡Œãªã„ã¯ãš)
            vertexai.init(project=project_id, location=region)
            # åˆ©ç”¨å¯èƒ½ãªãƒ¢ãƒ‡ãƒ«ã‚’ç¢ºèªãƒ»æŒ‡å®š (ä¾‹: imagegeneration@005)
            # æœ€æ–°ç‰ˆã¯ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã§ç¢ºèªæ¨å¥¨
            model = ImageGenerationModel.from_pretrained("imagegeneration@005")
            st.write(f"DEBUG: Calling Imagen with prompt: {prompt[:100]}...") # Debug

            # ç”»åƒç”Ÿæˆã‚’å®Ÿè¡Œ (ã‚µã‚¤ã‚ºæŒ‡å®šã¯ä¸€æ—¦çœç•¥ã—ã¦ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã«ä»»ã›ã‚‹)
            response = model.generate_images(
                prompt=prompt,
                number_of_images=1
                # size ã‚„ aspect_ratio ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã¯å¾Œã§è©¦ã™
            )
            st.write("DEBUG: Imagen response received.") # Debug

            if response.images:
                # ç”»åƒãƒ‡ãƒ¼ã‚¿ã‚’ãƒã‚¤ãƒˆå½¢å¼ã§å–å¾—
                image_bytes = response.images[0]._image_bytes
                st.write(f"DEBUG: Image bytes length: {len(image_bytes)}") # Debug
                return image_bytes
            else:
                st.error(f"Imagen APIã‚¨ãƒ©ãƒ¼: ç”»åƒãƒ‡ãƒ¼ã‚¿ãŒãƒ¬ã‚¹ãƒãƒ³ã‚¹ã«å«ã¾ã‚Œã¦ã„ã¾ã›ã‚“ã€‚Response: {response}")
                return None
        except Exception as e:
            st.error(f"Vertex AI Imagen APIã‚¨ãƒ©ãƒ¼: {e}")
            # èªè¨¼ã‚¨ãƒ©ãƒ¼ã®å ´åˆã€ADCã‚„ã‚µãƒ¼ãƒ“ã‚¹ã‚¢ã‚«ã‚¦ãƒ³ãƒˆè¨­å®šã‚’ç¢ºèªã™ã‚‹ã‚ˆã†ä¿ƒã™ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’è¿½åŠ ã—ã¦ã‚‚è‰¯ã„
            if "permission denied" in str(e).lower() or "quota" in str(e).lower():
                 st.error("èªè¨¼ã‚¨ãƒ©ãƒ¼ã¾ãŸã¯å‰²ã‚Šå½“ã¦é‡è¶…éã®å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™ã€‚GCPãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã®Vertex AI APIè¨­å®šã‚„èªè¨¼æƒ…å ±ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚")
            return None
    # â–²â–²â–² DALL-E 3 ã®ä»£ã‚ã‚Šã« Imagen ã‚’ä½¿ã†é–¢æ•° â–²â–²â–²

    # add_text_to_image (å¤‰æ›´ãªã—)
    def add_text_to_image(image, text, position, font_path, font_size, text_color=(0, 0, 0, 255)):
        # ... (é–¢æ•°å®šç¾©ã¯å‰å›ã¨åŒã˜) ...
        try:
            base = image.convert("RGBA"); txt_layer = Image.new("RGBA", base.size, (255, 255, 255, 0))
            try: font = ImageFont.truetype(font_path, font_size)
            except IOError: st.error(f"ãƒ•ã‚©ãƒ³ãƒˆæœªæ¤œå‡º/èª­è¾¼ä¸å¯: {font_path}"); return None
            except Exception as font_e: st.error(f"ãƒ•ã‚©ãƒ³ãƒˆèª­è¾¼ã‚¨ãƒ©ãƒ¼: {font_e}"); return None
            draw = ImageDraw.Draw(txt_layer); draw.text(position, text, font=font, fill=text_color)
            out = Image.alpha_composite(base, txt_layer); return out.convert("RGB")
        except Exception as e: st.error(f"ãƒ†ã‚­ã‚¹ãƒˆæç”»ã‚¨ãƒ©ãƒ¼: {e}"); return None


    # --- Streamlit App Main UI ---
    st.title("ğŸ¤– AIãƒãƒŠãƒ¼ãƒ©ãƒ•ç”Ÿæˆãƒ—ãƒ­ãƒˆã‚¿ã‚¤ãƒ— (GPT-4o + Imagen Ver.)") # ã‚¿ã‚¤ãƒˆãƒ«å¤‰æ›´
    st.write("æ§‹æˆæ¡ˆã®ç”»åƒã¨ãƒ†ã‚­ã‚¹ãƒˆæŒ‡ç¤ºã‹ã‚‰ã€AIãŒãƒãƒŠãƒ¼ãƒ©ãƒ•ç”»åƒã‚’ç”Ÿæˆã—ã¾ã™ã€‚")

    col1, col2 = st.columns(2)
    with col1:
        # ãƒ•ã‚©ãƒ¼ãƒ  (clear_on_submit ã¯å¤–ã—ãŸã¾ã¾)
        with st.form("input_form"):
            st.subheader("1. æ§‹æˆæ¡ˆã®ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰")
            uploaded_file = st.file_uploader(...) # Ellipsis for brevity
            st.subheader("2. ãƒ†ã‚­ã‚¹ãƒˆæŒ‡ç¤º")
            impression_text = st.text_input(...)
            details_text = st.text_area(...)
            st.subheader("3. ç”Ÿæˆã‚µã‚¤ã‚º")
            # â˜… Imagenã®ã‚µã‚¤ã‚ºæŒ‡å®šã¯è¤‡é›‘ãªãŸã‚ã€ä¸€æ—¦UIã‹ã‚‰ã¯å‰Šé™¤ã¾ãŸã¯ç„¡è¦–ã™ã‚‹
            #    ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã‚µã‚¤ã‚º (1024x1024?) ã§ç”Ÿæˆã•ã‚Œã‚‹
            # dalle_size = st.selectbox(...) # ã‚³ãƒ¡ãƒ³ãƒˆã‚¢ã‚¦ãƒˆã¾ãŸã¯å‰Šé™¤
            st.info("æ³¨æ„: ç¾åœ¨ã€ç”»åƒã‚µã‚¤ã‚ºã¯Imagenã®ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ(é€šå¸¸1024x1024)ã§ç”Ÿæˆã•ã‚Œã¾ã™ã€‚")
            generate_button = st.form_submit_button("ğŸ–¼ï¸ ãƒ©ãƒ•ç”»åƒã‚’ç”Ÿæˆã™ã‚‹", type="primary")

        if uploaded_file is not None:
             try: image = Image.open(uploaded_file); st.image(image, ...)
             except: pass

    # --- ãƒœã‚¿ãƒ³ãŒæŠ¼ã•ã‚ŒãŸå¾Œã®å‡¦ç† ---
    if generate_button:
        if uploaded_file is not None and details_text:
            layout_image_bytes = uploaded_file.getvalue()
            with col2:
                st.subheader("âš™ï¸ ç”Ÿæˆãƒ—ãƒ­ã‚»ã‚¹")
                # ã‚¹ãƒ”ãƒŠãƒ¼ã®ãƒ†ã‚­ã‚¹ãƒˆã‚‚å¤‰æ›´
                with st.spinner('AIãŒç”»åƒã‚’ç”Ÿæˆä¸­ã§ã™... (GPT-4o x2 + Imagen)'):
                    # Step 1: ãƒ¬ã‚¤ã‚¢ã‚¦ãƒˆè§£æ (GPT-4o) - å¤‰æ›´ãªã—
                    st.info("Step 1/3: æ§‹æˆæ¡ˆç”»åƒã‚’è§£æä¸­ (GPT-4o Vision)...")
                    layout_info = analyze_layout_with_gpt4o(layout_image_bytes, OPENAI_API_KEY, layout_analysis_prompt_text)
                    if layout_info:
                        with st.expander(...): st.text(layout_info)
                        # Step 2: ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆç”Ÿæˆ (GPT-4o) - å¤‰æ›´ãªã—
                        # æ³¨æ„: ç”Ÿæˆã•ã‚Œã‚‹ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã¯Imagenå‘ã‘ã«æœ€é©åŒ–ã•ã‚Œã¦ã„ãªã„å¯èƒ½æ€§ã‚ã‚Š
                        st.info("Step 2/3: ç”»åƒç”Ÿæˆç”¨ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’ç”Ÿæˆä¸­ (GPT-4o Text)...")
                        # ã‚µã‚¤ã‚ºæŒ‡å®šã¯Imagenå´ã§ç„¡è¦–ã•ã‚Œã‚‹ãŸã‚ã€ã“ã“ã§æ¸¡ã™å€¤ã¯å½¢å¼ã®ã¿å½±éŸ¿
                        image_gen_prompt = generate_dalle_prompt_with_gpt4o(layout_info, impression_text, details_text, "1024x1024", OPENAI_API_KEY, dalle_instruction_template_text) # å¤‰æ•°åå¤‰æ›´
                        if image_gen_prompt:
                             if "sorry" in image_gen_prompt.lower(): st.error("GPT-4oãƒ—ãƒ­ãƒ³ãƒ—ãƒˆç”Ÿæˆå¤±æ•—")
                             with st.expander("ç”Ÿæˆã•ã‚ŒãŸç”»åƒç”Ÿæˆãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ (GPT-4o)", expanded=True): st.text(image_gen_prompt)
                             if "sorry" not in image_gen_prompt.lower():
                                 # â–¼â–¼â–¼ Step 3: ç”»åƒç”Ÿæˆ (Imagen) â–¼â–¼â–¼
                                 st.info("Step 3/3: ç”»åƒã‚’ç”Ÿæˆä¸­ (Vertex AI Imagen)...")
                                 # GCP Project ID ã¨ Region ã‚’æ¸¡ã™
                                 image_bytes = generate_image_with_imagen(image_gen_prompt, GCP_PROJECT_ID, GCP_REGION)
                                 # â–²â–²â–² Step 3: ç”»åƒç”Ÿæˆ (Imagen) â–²â–²â–²

                                 if image_bytes: # Imagenã¯ãƒã‚¤ãƒˆåˆ—ã‚’è¿”ã™
                                      st.success("ğŸ‰ ç”»åƒç”ŸæˆãŒå®Œäº†ã—ã¾ã—ãŸï¼")
                                      st.subheader("ç”Ÿæˆã•ã‚ŒãŸãƒ©ãƒ•ç”»åƒ")
                                      # --- Step 4: ç”»åƒè¡¨ç¤º & ãƒ†ã‚­ã‚¹ãƒˆæç”» ---
                                      try:
                                           st.info("Step 4/4: ãƒ†ã‚­ã‚¹ãƒˆæç”»å‡¦ç†ä¸­...")
                                           # ãƒã‚¤ãƒˆãƒ‡ãƒ¼ã‚¿ã‹ã‚‰Pillowã‚¤ãƒ¡ãƒ¼ã‚¸ã‚’é–‹ã
                                           base_image = Image.open(BytesIO(image_bytes))

                                           # --- å›ºå®šãƒ†ã‚­ã‚¹ãƒˆæç”»ãƒ†ã‚¹ãƒˆ ---
                                           font_file_path = None
                                           try: # ãƒ•ã‚©ãƒ³ãƒˆãƒ‘ã‚¹å–å¾—
                                               script_dir = os.path.dirname(__file__)
                                               font_file_path = os.path.join(script_dir, "fonts", "NotoSansJP-Regular.ttf")
                                               if not os.path.exists(font_file_path): font_file_path = None
                                           except NameError: font_file_path = "fonts/NotoSansJP-Regular.ttf"; # Fallback
                                           if not os.path.exists(font_file_path): font_file_path = None

                                           if font_file_path:
                                                final_image = add_text_to_image(base_image, "ãƒ†ã‚¹ãƒˆæç”»(Imagen) ABC", (30,30), font_file_path, 50, (0,0,255,255)) # è‰²å¤‰æ›´
                                           else: final_image = base_image

                                           if final_image:
                                                st.image(final_image, caption='ç”Ÿæˆï¼‹ãƒ†ã‚­ã‚¹ãƒˆæç”» çµæœ (Imagen)', use_column_width=True)
                                                st.balloons()
                                           else: st.error("ãƒ†ã‚­ã‚¹ãƒˆæç”»ã‚¨ãƒ©ãƒ¼"); st.image(base_image, ...)

                                      except Exception as display_e:
                                           st.error(f"ç”»åƒå‡¦ç†/è¡¨ç¤ºã‚¨ãƒ©ãƒ¼: {display_e}")
                                           # No URL to display for Imagen bytes
        else:
             with col1: st.warning("ğŸ‘ˆ ç”»åƒã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã¨è©³ç´°æŒ‡ç¤ºã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ã€‚")

# --- Error handling for failed prompt/secret loading ---
elif not prompts_loaded: st.error("ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆèª­è¾¼å¤±æ•—ã€‚")
elif not secrets_ok: st.warning("Secretsé–¢é€£ã§å•é¡Œç™ºç”Ÿã€‚")
